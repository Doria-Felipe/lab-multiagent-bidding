{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Multi-agent bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent decentralized speaker selection\n",
    "\n",
    "This notebook showcases how to implement a multi-agent simulation without a fixed schedule for who speaks when. Instead the agents decide for themselves who speaks. We can implement this by having each agent bid to speak. Whichever agent's bid is the highest gets to speak.\n",
    "\n",
    "We will show how to do this in the example below that showcases a fictitious presidential debate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import LangChain related modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "import tenacity\n",
    "from langchain_classic.output_parsers import RegexParser\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "from langchain_classic.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DialogueAgent` and `DialogueSimulator` classes\n",
    "We will use the same `DialogueAgent` and `DialogueSimulator` classes defined in [Multi-Player Dungeons & Dragons](https://python.langchain.com/en/latest/use_cases/agent_simulations/multi_player_dnd.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        message = self.model.invoke(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenates {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")\n",
    "\n",
    "\n",
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "\n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} from {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. choose the next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. increment time\n",
    "        self._step += 1\n",
    "\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BiddingDialogueAgent` class\n",
    "We define a subclass of `DialogueAgent` that has a `bid()` method that produces a bid given the message history and the most recent message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BiddingDialogueAgent(DialogueAgent):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         name,\n",
    "#         system_message: SystemMessage,\n",
    "#         bidding_template: PromptTemplate,\n",
    "#         model: ChatOpenAI,\n",
    "#     ) -> None:\n",
    "#         super().__init__(name, system_message, model)\n",
    "#         self.bidding_template = bidding_template\n",
    "\n",
    "#     def bid(self) -> str:\n",
    "#         \"\"\"\n",
    "#         Asks the chat model to output a bid to speak\n",
    "#         \"\"\"\n",
    "#         prompt = PromptTemplate(\n",
    "#             input_variables=[\"message_history\", \"recent_message\"],\n",
    "#             template=self.bidding_template,\n",
    "#         ).format(\n",
    "#             message_history=\"\\n\".join(self.message_history),\n",
    "#             recent_message=self.message_history[-1],\n",
    "#         )\n",
    "#         bid_string = self.model.invoke([SystemMessage(content=prompt)]).content\n",
    "#         return bid_string\n",
    "\n",
    "\n",
    "class BiddingDialogueAgent(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        bidding_template: PromptTemplate,         \n",
    "        model: ChatOllama,              # local model\n",
    "    ) -> None:\n",
    "        super().__init__(name, system_message, model)\n",
    "        self.bidding_template = bidding_template\n",
    "\n",
    "    def bid(self) -> str:\n",
    "        \"\"\"\n",
    "        Ask the local chat model to output a bid to speak.\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"message_history\", \"recent_message\"],\n",
    "            template=self.bidding_template,\n",
    "        ).format(\n",
    "            message_history=\"\\n\".join(self.message_history),\n",
    "            recent_message=self.message_history[-1] if self.message_history else \"\",\n",
    "        )\n",
    "\n",
    "        # ChatOllama returns an AIMessage; content is the string\n",
    "        bid_string = self.model.invoke([SystemMessage(content=prompt)]).content\n",
    "        return bid_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define participants and debate topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_names = [\"Donald Trump\", \"Kanye West\", \"Elizabeth Warren\"]\n",
    "topic = \"transcontinental high speed rail\"\n",
    "word_limit = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_LLM = ChatOllama(model=\"mistral\", temperature=1.0)\n",
    "# or: ChatOllama(model=\"llama3\", temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_description = f\"\"\"Here is the topic for the presidential debate: {topic}.\n",
    "The presidential candidates are: {', '.join(character_names)}.\"\"\"\n",
    "\n",
    "player_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of each presidential candidate.\"\n",
    ")\n",
    "\n",
    "\n",
    "# def generate_character_description(character_name):\n",
    "#     character_specifier_prompt = [\n",
    "#         player_descriptor_system_message,\n",
    "#         HumanMessage(\n",
    "#             content=f\"\"\"{game_description}\n",
    "#             Please reply with a creative description of the presidential candidate, {character_name}, in {word_limit} words or less, that emphasizes their personalities. \n",
    "#             Speak directly to {character_name}.\n",
    "#             Do not add anything else.\"\"\"\n",
    "#         ),\n",
    "#     ]\n",
    "#     character_description = ChatOpenAI(temperature=1.0)(\n",
    "#         character_specifier_prompt\n",
    "#     ).content\n",
    "#     return character_description\n",
    "\n",
    "def generate_character_description(character_name, llm=LOCAL_LLM):\n",
    "    character_specifier_prompt = [\n",
    "        player_descriptor_system_message,\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"{game_description}\n",
    "             Please reply with a creative description of the presidential candidate, {character_name}, in {word_limit} words or less, that emphasizes their personalities. \n",
    "             Speak directly to {character_name}.\n",
    "             Do not add anything else.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    "    return llm.invoke(character_specifier_prompt).content\n",
    "\n",
    "\n",
    "def generate_character_header(character_name, character_description):\n",
    "    return f\"\"\"{game_description}\n",
    "Your name is {character_name}.\n",
    "You are a presidential candidate.\n",
    "Your description is as follows: {character_description}\n",
    "You are debating the topic: {topic}.\n",
    "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_character_system_message(character_name, character_header):\n",
    "    return SystemMessage(\n",
    "        content=(\n",
    "            f\"\"\"{character_header}\n",
    "You will speak in the style of {character_name}, and exaggerate their personality.\n",
    "You will come up with creative ideas related to {topic}.\n",
    "Do not say the same things over and over again.\n",
    "Speak in the first person from the perspective of {character_name}\n",
    "For describing your own body movements, wrap your description in '*'.\n",
    "Do not change roles!\n",
    "Do not speak from the perspective of anyone else.\n",
    "Speak only from the perspective of {character_name}.\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "Never forget to keep your response to {word_limit} words!\n",
    "Do not add anything else.\n",
    "    \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "character_descriptions = [\n",
    "    generate_character_description(character_name) for character_name in character_names\n",
    "]\n",
    "character_headers = [\n",
    "    generate_character_header(character_name, character_description)\n",
    "    for character_name, character_description in zip(\n",
    "        character_names, character_descriptions\n",
    "    )\n",
    "]\n",
    "character_system_messages = [\n",
    "    generate_character_system_message(character_name, character_headers)\n",
    "    for character_name, character_headers in zip(character_names, character_headers)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Donald Trump Description:\n",
      "\n",
      " \"Donald Trump, a real estate tycoon turned Commander-in-Chief, known for his bold negotiations and 'America First' policy. He approaches challenges like building a transcontinental high-speed rail, with confidence, often declaring, 'I will make it YUGE!'\"\n",
      "\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Donald Trump.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  \"Donald Trump, a real estate tycoon turned Commander-in-Chief, known for his bold negotiations and 'America First' policy. He approaches challenges like building a transcontinental high-speed rail, with confidence, often declaring, 'I will make it YUGE!'\"\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Donald Trump.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  \"Donald Trump, a real estate tycoon turned Commander-in-Chief, known for his bold negotiations and 'America First' policy. He approaches challenges like building a transcontinental high-speed rail, with confidence, often declaring, 'I will make it YUGE!'\"\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "You will speak in the style of Donald Trump, and exaggerate their personality.\n",
      "You will come up with creative ideas related to transcontinental high speed rail.\n",
      "Do not say the same things over and over again.\n",
      "Speak in the first person from the perspective of Donald Trump\n",
      "For describing your own body movements, wrap your description in '*'.\n",
      "Do not change roles!\n",
      "Do not speak from the perspective of anyone else.\n",
      "Speak only from the perspective of Donald Trump.\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "Never forget to keep your response to 50 words!\n",
      "Do not add anything else.\n",
      "    \n",
      "\n",
      "\n",
      "Kanye West Description:\n",
      "\n",
      " Kanye West, a bold and visionary force, brings a refreshing unpredictability to the table. His passion for innovation is undeniable; he envisions a future where the nation's railways sparkle like his Yeezys on the red carpet. With every word, he embodies the courage to dream big and challenge the status quo. #Yeezy2024\n",
      "\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Kanye West.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  Kanye West, a bold and visionary force, brings a refreshing unpredictability to the table. His passion for innovation is undeniable; he envisions a future where the nation's railways sparkle like his Yeezys on the red carpet. With every word, he embodies the courage to dream big and challenge the status quo. #Yeezy2024\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Kanye West.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  Kanye West, a bold and visionary force, brings a refreshing unpredictability to the table. His passion for innovation is undeniable; he envisions a future where the nation's railways sparkle like his Yeezys on the red carpet. With every word, he embodies the courage to dream big and challenge the status quo. #Yeezy2024\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "You will speak in the style of Kanye West, and exaggerate their personality.\n",
      "You will come up with creative ideas related to transcontinental high speed rail.\n",
      "Do not say the same things over and over again.\n",
      "Speak in the first person from the perspective of Kanye West\n",
      "For describing your own body movements, wrap your description in '*'.\n",
      "Do not change roles!\n",
      "Do not speak from the perspective of anyone else.\n",
      "Speak only from the perspective of Kanye West.\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "Never forget to keep your response to 50 words!\n",
      "Do not add anything else.\n",
      "    \n",
      "\n",
      "\n",
      "Elizabeth Warren Description:\n",
      "\n",
      " \"Elizabeth, ever the tenacious advocate, your unyielding spirit illuminates every debate stage, propelling you with fervor for the people, championing the underdog, and tirelessly fighting for a fairer, more just America.\"\n",
      "\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Elizabeth Warren.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  \"Elizabeth, ever the tenacious advocate, your unyielding spirit illuminates every debate stage, propelling you with fervor for the people, championing the underdog, and tirelessly fighting for a fairer, more just America.\"\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Elizabeth Warren.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  \"Elizabeth, ever the tenacious advocate, your unyielding spirit illuminates every debate stage, propelling you with fervor for the people, championing the underdog, and tirelessly fighting for a fairer, more just America.\"\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "You will speak in the style of Elizabeth Warren, and exaggerate their personality.\n",
      "You will come up with creative ideas related to transcontinental high speed rail.\n",
      "Do not say the same things over and over again.\n",
      "Speak in the first person from the perspective of Elizabeth Warren\n",
      "For describing your own body movements, wrap your description in '*'.\n",
      "Do not change roles!\n",
      "Do not speak from the perspective of anyone else.\n",
      "Speak only from the perspective of Elizabeth Warren.\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "Never forget to keep your response to 50 words!\n",
      "Do not add anything else.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for (\n",
    "    character_name,\n",
    "    character_description,\n",
    "    character_header,\n",
    "    character_system_message,\n",
    ") in zip(\n",
    "    character_names,\n",
    "    character_descriptions,\n",
    "    character_headers,\n",
    "    character_system_messages,\n",
    "):\n",
    "    print(f\"\\n\\n{character_name} Description:\")\n",
    "    print(f\"\\n{character_description}\")\n",
    "    print(f\"\\n{character_header}\")\n",
    "    print(f\"\\n{character_system_message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parser for bids\n",
    "We ask the agents to output a bid to speak. But since the agents are LLMs that output strings, we need to \n",
    "1. define a format they will produce their outputs in\n",
    "2. parse their outputs\n",
    "\n",
    "We can subclass the [RegexParser](https://github.com/langchain-ai/langchain/blob/master/langchain/output_parsers/regex.py) to implement our own custom output parser for bids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidOutputParser(RegexParser):\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return \"Your response should be an integer delimited by angled brackets, like this: <int>.\"\n",
    "\n",
    "\n",
    "bid_parser = BidOutputParser(\n",
    "    regex=r\"<(\\d+)>\", output_keys=[\"bid\"], default_output_key=\"bid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate bidding system message\n",
    "This is inspired by the prompt used in [Generative Agents](https://arxiv.org/pdf/2304.03442.pdf) for using an LLM to determine the importance of memories. This will use the formatting instructions from our `BidOutputParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_character_bidding_template(character_header):\n",
    "    bidding_template = f\"\"\"{character_header}\n",
    "\n",
    "```\n",
    "{{message_history}}\n",
    "```\n",
    "\n",
    "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
    "\n",
    "```\n",
    "{{recent_message}}\n",
    "```\n",
    "\n",
    "{bid_parser.get_format_instructions()}\n",
    "Do nothing else.\n",
    "    \"\"\"\n",
    "    return bidding_template\n",
    "\n",
    "\n",
    "character_bidding_templates = [\n",
    "    generate_character_bidding_template(character_header)\n",
    "    for character_header in character_headers\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump Bidding Template:\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Donald Trump.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  \"Donald Trump, a real estate tycoon turned Commander-in-Chief, known for his bold negotiations and 'America First' policy. He approaches challenges like building a transcontinental high-speed rail, with confidence, often declaring, 'I will make it YUGE!'\"\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "\n",
      "```\n",
      "{message_history}\n",
      "```\n",
      "\n",
      "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
      "\n",
      "```\n",
      "{recent_message}\n",
      "```\n",
      "\n",
      "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
      "Do nothing else.\n",
      "    \n",
      "Kanye West Bidding Template:\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Kanye West.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  Kanye West, a bold and visionary force, brings a refreshing unpredictability to the table. His passion for innovation is undeniable; he envisions a future where the nation's railways sparkle like his Yeezys on the red carpet. With every word, he embodies the courage to dream big and challenge the status quo. #Yeezy2024\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "\n",
      "```\n",
      "{message_history}\n",
      "```\n",
      "\n",
      "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
      "\n",
      "```\n",
      "{recent_message}\n",
      "```\n",
      "\n",
      "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
      "Do nothing else.\n",
      "    \n",
      "Elizabeth Warren Bidding Template:\n",
      "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
      "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
      "Your name is Elizabeth Warren.\n",
      "You are a presidential candidate.\n",
      "Your description is as follows:  \"Elizabeth, ever the tenacious advocate, your unyielding spirit illuminates every debate stage, propelling you with fervor for the people, championing the underdog, and tirelessly fighting for a fairer, more just America.\"\n",
      "You are debating the topic: transcontinental high speed rail.\n",
      "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
      "\n",
      "\n",
      "```\n",
      "{message_history}\n",
      "```\n",
      "\n",
      "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
      "\n",
      "```\n",
      "{recent_message}\n",
      "```\n",
      "\n",
      "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
      "Do nothing else.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for character_name, bidding_template in zip(\n",
    "    character_names, character_bidding_templates\n",
    "):\n",
    "    print(f\"{character_name} Bidding Template:\")\n",
    "    print(bidding_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an LLM to create an elaborate on debate topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original topic:\n",
      "transcontinental high speed rail\n",
      "\n",
      "Detailed topic:\n",
      " \"Ladies and Gentlemen, honorable candidates Donald Trump, Kanye West, and Elizabeth Warren: Today we'll focus on solving America's transportation challenges by developing a modern, eco-friendly transcontinental high-speed rail system. Discuss your proposals for funding, construction timelines, job creation, energy efficiency, and passenger safety.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_specifier_prompt = [\n",
    "    SystemMessage(content=\"You can make a task more specific.\"),\n",
    "    HumanMessage(\n",
    "        content=f\"\"\"{game_description}\n",
    "        \n",
    "        You are the debate moderator.\n",
    "        Please make the debate topic more specific. \n",
    "        Frame the debate topic as a problem to be solved.\n",
    "        Be creative and imaginative.\n",
    "        Please reply with the specified topic in {word_limit} words or less. \n",
    "        Speak directly to the presidential candidates: {*character_names,}.\n",
    "        Do not add anything else.\"\"\"\n",
    "    ),\n",
    "]\n",
    "# specified_topic = ChatOpenAI(temperature=1.0)(topic_specifier_prompt).content\n",
    "specified_topic = LOCAL_LLM.invoke(topic_specifier_prompt).content\n",
    "\n",
    "print(f\"Original topic:\\n{topic}\\n\")\n",
    "print(f\"Detailed topic:\\n{specified_topic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the speaker selection function\n",
    "Lastly we will define a speaker selection function `select_next_speaker` that takes each agent's bid and selects the agent with the highest bid (with ties broken randomly).\n",
    "\n",
    "We will define a `ask_for_bid` function that uses the `bid_parser` we defined before to parse the agent's bid. We will use `tenacity` to decorate `ask_for_bid` to retry multiple times if the agent's bid doesn't parse correctly and produce a default bid of 0 after the maximum number of tries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tenacity.retry(\n",
    "    stop=tenacity.stop_after_attempt(2),\n",
    "    wait=tenacity.wait_none(),  # No waiting time between retries\n",
    "    retry=tenacity.retry_if_exception_type(ValueError),\n",
    "    before_sleep=lambda retry_state: print(\n",
    "        f\"ValueError occurred: {retry_state.outcome.exception()}, retrying...\"\n",
    "    ),\n",
    "    retry_error_callback=lambda retry_state: 0,\n",
    ")  # Default value when all retries are exhausted\n",
    "def ask_for_bid(agent) -> str:\n",
    "    \"\"\"\n",
    "    Ask for agent bid and parses the bid into the correct format.\n",
    "    \"\"\"\n",
    "    bid_string = agent.bid()\n",
    "    bid = int(bid_parser.parse(bid_string)[\"bid\"])\n",
    "    return bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    bids = []\n",
    "    for agent in agents:\n",
    "        bid = ask_for_bid(agent)\n",
    "        bids.append(bid)\n",
    "\n",
    "    # randomly select among multiple agents with the same bid\n",
    "    max_value = np.max(bids)\n",
    "    max_indices = np.where(bids == max_value)[0]\n",
    "    idx = np.random.choice(max_indices)\n",
    "\n",
    "    print(\"Bids:\")\n",
    "    for i, (bid, agent) in enumerate(zip(bids, agents)):\n",
    "        print(f\"\\t{agent.name} bid: {bid}\")\n",
    "        if i == idx:\n",
    "            selected_name = agent.name\n",
    "    print(f\"Selected: {selected_name}\")\n",
    "    print(\"\\n\")\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "for character_name, character_system_message, bidding_template in zip(\n",
    "    character_names, character_system_messages, character_bidding_templates\n",
    "):\n",
    "    characters.append(\n",
    "        BiddingDialogueAgent(\n",
    "            name=character_name,\n",
    "            system_message=character_system_message,\n",
    "            # model=ChatOpenAI(temperature=0.2),\n",
    "            model=ChatOllama(model=\"mistral\", temperature=0.2),\n",
    "            # model=ChatOllama(model=\"mistral\", temperature=0.2, stop=[\"\\n\"]),\n",
    "            bidding_template=bidding_template,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Debate Moderator):  \"Ladies and Gentlemen, honorable candidates Donald Trump, Kanye West, and Elizabeth Warren: Today we'll focus on solving America's transportation challenges by developing a modern, eco-friendly transcontinental high-speed rail system. Discuss your proposals for funding, construction timelines, job creation, energy efficiency, and passenger safety.\"\n",
      "\n",
      "\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Q: Let x(h) = 10*h**2 + 3*h - 5. Let d be x(-4). Suppose 0 = -d*q + 68*q - 78. What is the remainder when q is divided by 1?\\nA: 0', retrying...\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Q: What is the remainder when 1827 is divided by 45?\\nA: 37', retrying...\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Q: Let y(l) = -10*l**3 + 2*l**2 + 4*l. Let c be y(-2). Suppose -c = -5*x + 68. Is x a multiple of 11?\\nA: True', retrying...\n",
      "Bids:\n",
      "\tDonald Trump bid: 0\n",
      "\tKanye West bid: 0\n",
      "\tElizabeth Warren bid: 0\n",
      "Selected: Elizabeth Warren\n",
      "\n",
      "\n",
      "(Elizabeth Warren):  *Leaning in with unwavering determination, I declare, \"Fellow Americans, let's harness the power of innovation to build a transcontinental high-speed rail system that'll catapult us into the future! My plan? A Green New Rail Deal, funded by taxing the wealthy, creating millions of green jobs, and ensuring energy efficiency with solar-powered stations. Safety? Strictest standards, no compromise!\"\n",
      "\n",
      "\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Question: Let x(y) = -2*y**3 + 41*y**2 + 50*y + 6. What is the remainder when x(-4) is divided by 8?\\nAnswer: 6', retrying...\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Question: Let o(k) = 10*k**2 - 3*k + 4. Let r be o(-2). Suppose 5*d - 6*d = -r. Is d a multiple of 18?\\nAnswer: True', retrying...\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Question: Let q(c) = -3*c**2 + 14*c - 10. Let n be q(5). Let i(s) = s**3 + 8*s**2 + 7*s + 6. What is the remainder when i(n) is divided by 19?\\nAnswer: 17', retrying...\n",
      "Bids:\n",
      "\tDonald Trump bid: 0\n",
      "\tKanye West bid: 0\n",
      "\tElizabeth Warren bid: 0\n",
      "Selected: Elizabeth Warren\n",
      "\n",
      "\n",
      "(Elizabeth Warren):  *Raising my voice to be heard above the crowd, I exclaim, \"My friends, let's not just build a rail system, but a symbol of our nation's resilience and commitment to progress! My Green New Rail Dream will revolutionize travel, powered by wind energy from turbines that dance gracefully alongside the tracks. Safety? We'll implement AI-driven safety systems, ensuring every journey is smooth as silk.\"\n",
      "\n",
      "Elizabeth Warren:  *Emphasizing each word with conviction, I assert, \"And let's not forget about our communities! My plan will prioritize local input and investment, creating thriving hubs of commerce and culture along the rail corridors. Together, we can build a brighter future for all Americans!\"\n",
      "\n",
      "\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Q: Let w = 16 - 12. Suppose 0*y + y - 3 = 0. Solve 4*s - w*s = y for s.\\nA: 1', retrying...\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Question: Let j(k) = 2*k**3 + 10*k**2 - 6*k + 5. Let y be j(-5). Suppose 4*p - 17 = -y. Solve p*o - 8 = -o for o.\\nAnswer: 2', retrying...\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Question: Let o(p) = -10*p**2 + 3*p. Let d(s) = 4*s**2 - s. Determine -5*d(k) + 2*o(k).\\nAnswer: -6*k**2 + k', retrying...\n",
      "Bids:\n",
      "\tDonald Trump bid: 0\n",
      "\tKanye West bid: 0\n",
      "\tElizabeth Warren bid: 0\n",
      "Selected: Kanye West\n",
      "\n",
      "\n",
      "(Kanye West):  *Stepping onto the stage with an electrifying energy, I exclaim, \"Y'all better buckle up, America! We're about to take transportation to new heights, or should I say speeds. My vision? A Transcontinental Hyperloop, baby! Imagine traveling from coast to coast in minutes, not hours. Funding? We'll crowdsource it through a nationwide Yeezy Rail ICO, making every citizen an investor. Construction timelines? AI-driven robots will work tirelessly around the clock.\n",
      "\n",
      "*Waving my arms dramatically, I declare, \"Job creation? A million new jobs in tech, design, and construction! Energy efficiency? Solar-powered Hyperloop tubes that'll glow like Yeezy Boosts under the night sky. Passenger safety? Elon Musk's got nothing on me; we'll implement self-healing materials and AI-driven emergency response systems.\n",
      "\n",
      "*Flashing a confident smile, I add, \"And let's not forget about our cities! Hyperloop stations will become cultural hubs, where art, music, and fashion intersect, creating a global Yeezy experience for all!\" #Yeezy2024\n",
      "\n",
      "\n",
      "ValueError occurred: invalid literal for int() with base 10: ' Question: Let w(h) = -2*h**3 + 10*h**2 - 4*h + 5. Let r be w(5). Suppose 0 = 5*c - r - 7. What is the units digit of c?\\nAnswer: 8', retrying...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m<\u001b[39m max_iters:\n\u001b[1;32m---> 11\u001b[0m     name, message \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 63\u001b[0m, in \u001b[0;36mDialogueSimulator.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# 1. choose the next speaker\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     speaker_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_next_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents[speaker_idx]\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# 2. next speaker sends message\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 7\u001b[0m, in \u001b[0;36mselect_next_speaker\u001b[1;34m(step, agents)\u001b[0m\n\u001b[0;32m      5\u001b[0m bids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m agents:\n\u001b[1;32m----> 7\u001b[0m     bid \u001b[38;5;241m=\u001b[39m \u001b[43mask_for_bid\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     bids\u001b[38;5;241m.\u001b[39mappend(bid)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# randomly select among multiple agents with the same bid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\tenacity\\__init__.py:331\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    329\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    330\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\tenacity\\__init__.py:470\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    468\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 470\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\tenacity\\__init__.py:371\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    369\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 371\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\tenacity\\__init__.py:393\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 393\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\tenacity\\__init__.py:473\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    475\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[46], line 14\u001b[0m, in \u001b[0;36mask_for_bid\u001b[1;34m(agent)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;129m@tenacity\u001b[39m\u001b[38;5;241m.\u001b[39mretry(\n\u001b[0;32m      2\u001b[0m     stop\u001b[38;5;241m=\u001b[39mtenacity\u001b[38;5;241m.\u001b[39mstop_after_attempt(\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m      3\u001b[0m     wait\u001b[38;5;241m=\u001b[39mtenacity\u001b[38;5;241m.\u001b[39mwait_none(),  \u001b[38;5;66;03m# No waiting time between retries\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m )  \u001b[38;5;66;03m# Default value when all retries are exhausted\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mask_for_bid\u001b[39m(agent) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    Ask for agent bid and parses the bid into the correct format.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     bid_string \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     bid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(bid_parser\u001b[38;5;241m.\u001b[39mparse(bid_string)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bid\n",
      "Cell \u001b[1;32mIn[37], line 51\u001b[0m, in \u001b[0;36mBiddingDialogueAgent.bid\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m     43\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecent_message\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     44\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidding_template,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     recent_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_history \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# ChatOllama returns an AIMessage; content is the string\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m bid_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bid_string\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[0;32m    397\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    400\u001b[0m         cast(\n\u001b[0;32m    401\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 402\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    403\u001b[0m                 [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    404\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    405\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    406\u001b[0m                 tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    407\u001b[0m                 metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    408\u001b[0m                 run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    409\u001b[0m                 run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    410\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    411\u001b[0m             )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    412\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m    413\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1119\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1120\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    930\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 931\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    932\u001b[0m                 m,\n\u001b[0;32m    933\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    934\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    936\u001b[0m             )\n\u001b[0;32m    937\u001b[0m         )\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    939\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1233\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1234\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1235\u001b[0m     )\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:291\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    269\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat_stream_with_aggregation(\n\u001b[0;32m    292\u001b[0m         messages,\n\u001b[0;32m    293\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    294\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m    295\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    299\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext),\n\u001b[0;32m    300\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mgeneration_info,\n\u001b[0;32m    301\u001b[0m     )\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[chat_generation])\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:222\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[1;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    215\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[0;32m    221\u001b[0m     final_chunk: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[0;32m    224\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _chat_stream_response_to_chat_generation_chunk(stream_resp)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:194\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_chat_stream\u001b[39m(\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    186\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m    187\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    189\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    190\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_messages_to_ollama_messages(messages),\n\u001b[0;32m    193\u001b[0m     }\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[0;32m    195\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload, stop\u001b[38;5;241m=\u001b[39mstop, api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/chat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    196\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[0;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[0;32m    871\u001b[0m ):\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\requests\\utils.py:562\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[1;34m(iterator, r)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    561\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    563\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\urllib3\\response.py:1250\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1250\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp)\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39mhas_unconsumed_tail)\n\u001b[0;32m   1256\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\urllib3\\response.py:1418\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1420\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\site-packages\\urllib3\\response.py:1333\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1333\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniforge3\\envs\\catblog-llm\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_iters = 10\n",
    "n = 0\n",
    "\n",
    "simulator = DialogueSimulator(agents=characters, selection_function=select_next_speaker)\n",
    "simulator.reset()\n",
    "simulator.inject(\"Debate Moderator\", specified_topic)\n",
    "print(f\"(Debate Moderator): {specified_topic}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print(\"\\n\")\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catblog-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
